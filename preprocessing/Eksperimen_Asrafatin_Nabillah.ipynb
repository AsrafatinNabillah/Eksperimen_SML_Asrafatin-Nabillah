{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Perkenalan Dataset**\n"
      ],
      "metadata": {
        "id": "kZLRMFl0JyyQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data ini merupakan data harian Indeks\n",
        "Standar Pencemar Udara (ISPU) Di Kabupaten Gresik pada periode 11 Maret 2024\n",
        "hingga 18 Agustus 2025, yang diambil dari situs resmi\n",
        "https://aqicn.org/station/@474973/, yakni platform penyedia informasi real-time\n",
        "mengenai Indeks Standar Pencemar Udara (ISPU) di Kabupaten Gresik\n"
      ],
      "metadata": {
        "id": "hssSDn-5n3HR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Import Library**"
      ],
      "metadata": {
        "id": "fKADPWcFKlj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "BlmvjLY9M4Yj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Memuat Dataset**"
      ],
      "metadata": {
        "id": "f3YIEnAFKrKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Upload file dataset dari perangkat Anda:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "print(\"\\nFile yang berhasil diupload:\")\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"- {filename} ({len(uploaded[filename])} bytes)\")\n",
        "\n",
        "print(f\"\\nTotal {len(uploaded)} file berhasil diupload.\")\n",
        "\n",
        "# Ambil nama file yang benar dari dictionary uploaded\n",
        "filename = list(uploaded.keys())[0]\n",
        "df = pd.read_excel(filename)\n",
        "\n",
        "print(f\"\\n5 baris pertama dari {filename}:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "JqlsIdh72NVS",
        "outputId": "83fd6787-6f46-4ebe-fe65-f36d45e57694"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Upload file dataset dari perangkat Anda:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b3f5b6d2-801e-454a-941b-357790a4f884\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b3f5b6d2-801e-454a-941b-357790a4f884\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving DataISPU_raw.xlsx to DataISPU_raw.xlsx\n",
            "\n",
            "File yang berhasil diupload:\n",
            "- DataISPU_raw.xlsx (38153 bytes)\n",
            "\n",
            "Total 1 file berhasil diupload.\n",
            "\n",
            "5 baris pertama dari DataISPU_raw.xlsx:\n",
            "   No    CO    NO2     O3  PM10  PM2.5    SO2  ISPU\n",
            "0   1  0.28  12.98   8.15  4.30   6.29  23.70    23\n",
            "1   2  0.28  14.61   8.32  0.48   7.06  23.40    23\n",
            "2   3  0.28  18.19  10.25  2.98   9.80  22.00    32\n",
            "3   4  0.28  12.85   8.00  9.90   7.57  21.80    24\n",
            "4   5  0.28  14.75   8.00  7.79   6.03  21.08    20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Exploratory Data Analysis (EDA)**\n",
        "\n"
      ],
      "metadata": {
        "id": "bgZkbJLpK9UR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"4. EXPLORATORY DATA ANALYSIS (EDA)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 1. Informasi dasar dataset\n",
        "print(\"\\n1. INFORMASI DASAR DATASET\")\n",
        "print(\"-\" * 30)\n",
        "print(f\"Jumlah baris: {df.shape[0]}\")\n",
        "print(f\"Jumlah kolom: {df.shape[1]}\")\n",
        "\n",
        "# 2. Nama kolom\n",
        "print(\"\\n2. NAMA KOLOM\")\n",
        "print(\"-\" * 30)\n",
        "for i, col in enumerate(df.columns, 1):\n",
        "    print(f\"{i}. {col}\")\n",
        "\n",
        "# 3. Tipe data setiap kolom\n",
        "print(\"\\n3. TIPE DATA\")\n",
        "print(\"-\" * 30)\n",
        "print(df.dtypes)\n",
        "\n",
        "# 4. Statistik deskriptif untuk kolom numerik\n",
        "print(\"\\n4. STATISTIK DESKRIPTIF (NUMERIK)\")\n",
        "print(\"-\" * 30)\n",
        "print(df.describe())\n",
        "\n",
        "# 5. Cek missing values\n",
        "print(\"\\n5. MISSING VALUES\")\n",
        "print(\"-\" * 30)\n",
        "missing_values = df.isnull().sum()\n",
        "missing_percentage = (missing_values / len(df)) * 100\n",
        "missing_df = pd.DataFrame({\n",
        "    'Missing Values': missing_values,\n",
        "    'Percentage (%)': missing_percentage\n",
        "})\n",
        "print(missing_df[missing_df['Missing Values'] > 0])\n",
        "\n",
        "if missing_df[missing_df['Missing Values'] > 0].empty:\n",
        "    print(\"Tidak ada missing values dalam dataset.\")\n",
        "\n",
        "# 6. Cek duplikat\n",
        "print(\"\\n6. DUPLIKAT DATA\")\n",
        "print(\"-\" * 30)\n",
        "duplicates = df.duplicated().sum()\n",
        "print(f\"Jumlah baris duplikat: {duplicates}\")\n",
        "\n",
        "# 7. Distribusi data untuk beberapa kolom pertama (jika numerik)\n",
        "print(\"\\n7. DISTRIBUSI DATA (5 KOLOM PERTAMA NUMERIK)\")\n",
        "print(\"-\" * 30)\n",
        "numeric_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "if len(numeric_cols) > 0:\n",
        "    for i, col in enumerate(numeric_cols[:5]):  # Hanya 5 kolom pertama\n",
        "        print(f\"\\nKolom: {col}\")\n",
        "        print(f\"  Mean: {df[col].mean():.2f}\")\n",
        "        print(f\"  Median: {df[col].median():.2f}\")\n",
        "        print(f\"  Std Dev: {df[col].std():.2f}\")\n",
        "        print(f\"  Min: {df[col].min():.2f}\")\n",
        "        print(f\"  Max: {df[col].max():.2f}\")\n",
        "else:\n",
        "    print(\"Tidak ada kolom numerik dalam dataset.\")\n",
        "\n",
        "# 8. Unique values untuk kolom kategorikal\n",
        "print(\"\\n8. UNIQUE VALUES (KOLOM KATEGORIKAL)\")\n",
        "print(\"-\" * 30)\n",
        "categorical_cols = df.select_dtypes(include=['object']).columns\n",
        "if len(categorical_cols) > 0:\n",
        "    for i, col in enumerate(categorical_cols[:5]):  # Hanya 5 kolom pertama\n",
        "        unique_count = df[col].nunique()\n",
        "        print(f\"\\nKolom: {col}\")\n",
        "        print(f\"  Jumlah unique values: {unique_count}\")\n",
        "        if unique_count <= 10:  # Tampilkan values jika tidak terlalu banyak\n",
        "            print(f\"  Values: {df[col].unique().tolist()}\")\n",
        "else:\n",
        "    print(\"Tidak ada kolom kategorikal dalam dataset.\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"EDA SELESAI - DATA MASIH RAW (TANPA PREPROCESSING)\")\n",
        "print(\"=\" * 50)"
      ],
      "metadata": {
        "id": "dKeejtvxM6X1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c1f9094-d565-40ef-8778-020fbba9c849"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "4. EXPLORATORY DATA ANALYSIS (EDA)\n",
            "==================================================\n",
            "\n",
            "1. INFORMASI DASAR DATASET\n",
            "------------------------------\n",
            "Jumlah baris: 526\n",
            "Jumlah kolom: 8\n",
            "\n",
            "2. NAMA KOLOM\n",
            "------------------------------\n",
            "1. No\n",
            "2. CO\n",
            "3. NO2\n",
            "4. O3\n",
            "5. PM10\n",
            "6. PM2.5\n",
            "7. SO2\n",
            "8. ISPU\n",
            "\n",
            "3. TIPE DATA\n",
            "------------------------------\n",
            "No         int64\n",
            "CO       float64\n",
            "NO2      float64\n",
            "O3       float64\n",
            "PM10     float64\n",
            "PM2.5    float64\n",
            "SO2      float64\n",
            "ISPU       int64\n",
            "dtype: object\n",
            "\n",
            "4. STATISTIK DESKRIPTIF (NUMERIK)\n",
            "------------------------------\n",
            "              No          CO         NO2          O3        PM10       PM2.5  \\\n",
            "count  526.00000  526.000000  526.000000  526.000000  526.000000  526.000000   \n",
            "mean   263.50000    0.092129   16.335589   13.389373   18.554259   14.556198   \n",
            "std    151.98739    0.096765    9.466022   13.015074    8.467732    6.126203   \n",
            "min      1.00000    0.010000    3.000000    2.000000    0.480000    3.510000   \n",
            "25%    132.25000    0.050000    9.742500    7.750000   12.920000   10.765000   \n",
            "50%    263.50000    0.060000   11.670000    7.770000   17.370000   13.135000   \n",
            "75%    394.75000    0.080000   20.107500   10.330000   23.232500   16.945000   \n",
            "max    526.00000    0.490000   49.430000  102.200000   70.630000   52.170000   \n",
            "\n",
            "              SO2        ISPU  \n",
            "count  526.000000  526.000000  \n",
            "mean    36.546692   45.804183  \n",
            "std      5.068994    9.863336  \n",
            "min     20.880000   20.000000  \n",
            "25%     35.410000   38.000000  \n",
            "50%     38.190000   43.000000  \n",
            "75%     39.827500   52.000000  \n",
            "max     47.380000   96.000000  \n",
            "\n",
            "5. MISSING VALUES\n",
            "------------------------------\n",
            "Empty DataFrame\n",
            "Columns: [Missing Values, Percentage (%)]\n",
            "Index: []\n",
            "Tidak ada missing values dalam dataset.\n",
            "\n",
            "6. DUPLIKAT DATA\n",
            "------------------------------\n",
            "Jumlah baris duplikat: 0\n",
            "\n",
            "7. DISTRIBUSI DATA (5 KOLOM PERTAMA NUMERIK)\n",
            "------------------------------\n",
            "\n",
            "Kolom: No\n",
            "  Mean: 263.50\n",
            "  Median: 263.50\n",
            "  Std Dev: 151.99\n",
            "  Min: 1.00\n",
            "  Max: 526.00\n",
            "\n",
            "Kolom: CO\n",
            "  Mean: 0.09\n",
            "  Median: 0.06\n",
            "  Std Dev: 0.10\n",
            "  Min: 0.01\n",
            "  Max: 0.49\n",
            "\n",
            "Kolom: NO2\n",
            "  Mean: 16.34\n",
            "  Median: 11.67\n",
            "  Std Dev: 9.47\n",
            "  Min: 3.00\n",
            "  Max: 49.43\n",
            "\n",
            "Kolom: O3\n",
            "  Mean: 13.39\n",
            "  Median: 7.77\n",
            "  Std Dev: 13.02\n",
            "  Min: 2.00\n",
            "  Max: 102.20\n",
            "\n",
            "Kolom: PM10\n",
            "  Mean: 18.55\n",
            "  Median: 17.37\n",
            "  Std Dev: 8.47\n",
            "  Min: 0.48\n",
            "  Max: 70.63\n",
            "\n",
            "8. UNIQUE VALUES (KOLOM KATEGORIKAL)\n",
            "------------------------------\n",
            "Tidak ada kolom kategorikal dalam dataset.\n",
            "\n",
            "==================================================\n",
            "EDA SELESAI - DATA MASIH RAW (TANPA PREPROCESSING)\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Data Preprocessing**"
      ],
      "metadata": {
        "id": "cpgHfgnSK3ip"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"=\" * 50)\n",
        "print(\"DATA PREPROCESSING UNTUK RANDOM FOREST CLASSIFIER\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Simpan data asli\n",
        "df_original = df.copy()\n",
        "\n",
        "# 0. TENTUKAN TARGET TERLEBIH DAHULU\n",
        "print(\"\\n0. MENENTUKAN TARGET VARIABEL\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Hapus kolom 'No' karena tidak diperlukan\n",
        "if 'No' in df.columns:\n",
        "    df = df.drop('No', axis=1)\n",
        "    print(\"Kolom 'No' telah dihapus (tidak diperlukan untuk ML)\")\n",
        "\n",
        "# Buat target kategorikal dari ISPU (jika belum ada)\n",
        "if 'ISPU_Kategori' not in df.columns and 'ISPU' in df.columns:\n",
        "    print(\"Membuat kategori ISPU dari nilai ISPU...\")\n",
        "\n",
        "    # Definisikan bins sesuai standar ISPU Indonesia\n",
        "    bins = [0, 50, 100, 200, 300, float('inf')]\n",
        "    labels = ['Baik', 'Sedang', 'Tidak Sehat', 'Sangat Tidak Sehat', 'Berbahaya']\n",
        "\n",
        "    df['ISPU_Kategori'] = pd.cut(df['ISPU'], bins=bins, labels=labels, include_lowest=True)\n",
        "\n",
        "    # Hapus kolom ISPU numerik jika ingin klasifikasi murni\n",
        "    # df = df.drop('ISPU', axis=1)  # Opsional: hapus jika tidak ingin leak informasi\n",
        "\n",
        "    print(\"Distribusi kategori ISPU:\")\n",
        "    print(df['ISPU_Kategori'].value_counts().sort_index())\n",
        "    print(f\"\\nJumlah kategori: {df['ISPU_Kategori'].nunique()}\")\n",
        "\n",
        "    # Cek imbalance\n",
        "    class_dist = df['ISPU_Kategori'].value_counts(normalize=True) * 100\n",
        "    print(\"\\nDistribusi kelas (%):\")\n",
        "    for category, percentage in class_dist.items():\n",
        "        print(f\"  {category}: {percentage:.1f}%\")\n",
        "\n",
        "# 1. HANDLING MISSING VALUES (Diperbaiki)\n",
        "print(\"\\n1. PENANGANAN MISSING VALUES\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "missing_before = df.isnull().sum()\n",
        "if missing_before.sum() > 0:\n",
        "    print(f\"Total missing values: {missing_before.sum()}\")\n",
        "    print(missing_before[missing_before > 0])\n",
        "\n",
        "    # PENTING: Pisahkan fitur dan target sebelum imputasi\n",
        "    features = ['CO', 'NO2', 'O3', 'PM10', 'PM2.5', 'SO2']\n",
        "    target = 'ISPU_Kategori'\n",
        "\n",
        "    # Untuk data kecil (526 baris), lebih baik drop NA daripada imputasi\n",
        "    df_cleaned = df.dropna()\n",
        "    rows_dropped = df.shape[0] - df_cleaned.shape[0]\n",
        "\n",
        "    print(f\"\\nMenggunakan dropna() karena data hanya {df.shape[0]} baris\")\n",
        "    print(f\"Baris yang dihapus: {rows_dropped} ({rows_dropped/df.shape[0]*100:.1f}%)\")\n",
        "\n",
        "    df = df_cleaned\n",
        "else:\n",
        "    print(\"Tidak ada missing values\")\n",
        "\n",
        "# 2. HANDLING DUPLICATES\n",
        "print(\"\\n2. PENANGANAN DATA DUPLIKAT\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "duplicates = df.duplicated().sum()\n",
        "if duplicates > 0:\n",
        "    print(f\"Menghapus {duplicates} data duplikat\")\n",
        "    df = df.drop_duplicates()\n",
        "    print(f\"Sisa {df.shape[0]} baris data\")\n",
        "else:\n",
        "    print(\"Tidak ada data duplikat\")\n",
        "\n",
        "# 3. OUTLIER DETECTION (Hanya Informasi - Jangan dihapus!)\n",
        "print(\"\\n3. ANALISIS OUTLIER (Hanya Informasi)\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Random Forest robust terhadap outlier, jadi hanya untuk analisis\n",
        "numeric_cols = ['CO', 'NO2', 'O3', 'PM10', 'PM2.5', 'SO2']\n",
        "outlier_info = {}\n",
        "\n",
        "for col in numeric_cols:\n",
        "    if col in df.columns:\n",
        "        Q1 = df[col].quantile(0.25)\n",
        "        Q3 = df[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower = Q1 - 1.5 * IQR\n",
        "        upper = Q3 + 1.5 * IQR\n",
        "\n",
        "        outliers = df[(df[col] < lower) | (df[col] > upper)]\n",
        "        perc = (len(outliers) / len(df)) * 100\n",
        "\n",
        "        outlier_info[col] = {\n",
        "            'count': len(outliers),\n",
        "            'percentage': perc,\n",
        "            'min': df[col].min(),\n",
        "            'max': df[col].max()\n",
        "        }\n",
        "\n",
        "print(\"Outlier per kolom (batas IQR 1.5):\")\n",
        "for col, info in outlier_info.items():\n",
        "    print(f\"  {col:6}: {info['count']:3} outlier ({info['percentage']:5.1f}%)\")\n",
        "\n",
        "# 4. ENCODING TARGET (Jika diperlukan untuk modeling)\n",
        "print(\"\\n4. PREPARASI TARGET VARIABEL\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "if 'ISPU_Kategori' in df.columns:\n",
        "    # Simpan mapping untuk interpretasi nanti\n",
        "    category_mapping = {cat: idx for idx, cat in enumerate(df['ISPU_Kategori'].cat.categories)}\n",
        "    print(\"Mapping kategori ke angka:\")\n",
        "    for category, idx in category_mapping.items():\n",
        "        print(f\"  {idx}: {category}\")\n",
        "\n",
        "    # Untuk analisis, kita bisa encode nanti di pipeline\n",
        "    print(\"\\nTarget siap untuk modeling dengan LabelEncoder\")\n",
        "\n",
        "# 5. PREPARASI FEATURE DAN TARGET\n",
        "print(\"\\n5. PREPARASI FEATURE DAN TARGET\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# Definisikan fitur dan target\n",
        "X = df[['CO', 'NO2', 'O3', 'PM10', 'PM2.5', 'SO2']]\n",
        "y = df['ISPU_Kategori']\n",
        "\n",
        "print(f\"Jumlah fitur: {X.shape[1]}\")\n",
        "print(f\"Jumlah sampel: {X.shape[0]}\")\n",
        "print(f\"Target classes: {y.nunique()}\")\n",
        "\n",
        "# 6. TRAIN-TEST SPLIT (STRATIFIED)\n",
        "print(\"\\n6. TRAIN-TEST SPLIT (STRATIFIED)\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Gunakan stratified split karena data tidak seimbang\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y,\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        "    stratify=y  # PENTING: pertahankan distribusi kelas\n",
        ")\n",
        "\n",
        "print(f\"Train set: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
        "print(f\"Test set:  {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
        "\n",
        "print(\"\\nDistribusi kelas di Train set:\")\n",
        "print(y_train.value_counts().sort_index())\n",
        "print(\"\\nDistribusi kelas di Test set:\")\n",
        "print(y_test.value_counts().sort_index())\n",
        "\n",
        "# 7. SCALING (OPSIONAL - Random Forest tidak butuh)\n",
        "print(\"\\n7. SCALING (OPSIONAL - Hanya untuk referensi)\")\n",
        "print(\"-\" * 30)\n",
        "\n",
        "print(\"Random Forest TIDAK MEMERLUKAN scaling karena berbasis tree\")\n",
        "print(\"Namun, scaling bisa membantu visualisasi atau algoritma lain\")\n",
        "\n",
        "# 8. FINAL SUMMARY\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"RINGKASAN AKHIR PREPROCESSING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "print(f\"\\nDataset akhir:\")\n",
        "print(f\"  Jumlah baris: {df.shape[0]}\")\n",
        "print(f\"  Jumlah kolom: {df.shape[1]}\")\n",
        "print(f\"  Fitur: {list(X.columns)}\")\n",
        "print(f\"  Target: ISPU_Kategori\")\n",
        "\n",
        "print(\"\\nStatistik dataset:\")\n",
        "print(f\"  Missing values: {df.isnull().sum().sum()}\")\n",
        "print(f\"  Duplicates: {df.duplicated().sum()}\")\n",
        "\n",
        "print(\"\\nData siap untuk Random Forest Classifier!\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# 8. FINAL SUMMARY\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"RINGKASAN AKHIR PREPROCESSING\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Save the cleaned data to a CSV file\n",
        "output_file = \"DataISPU_preprocessing.csv\"\n",
        "df.to_csv(output_file, index=False)\n",
        "print(f\"Data telah disimpan ke {output_file}\")\n",
        "\n",
        "# Provide a download link\n",
        "files.download(output_file)\n",
        "\n",
        "print(f\"\\nDataset akhir:\")\n",
        "print(f\"  Jumlah baris: {df.shape[0]}\")\n",
        "print(f\"  Jumlah kolom: {df.shape[1]}\")\n",
        "print(f\"  Fitur: {list(X.columns)}\")\n",
        "print(f\"  Target: ISPU_Kategori\")"
      ],
      "metadata": {
        "id": "Og8pGV0-iDLz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50737d70-cf4f-4bee-c89c-a86c7d2be277"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================================\n",
            "DATA PREPROCESSING UNTUK RANDOM FOREST CLASSIFIER\n",
            "==================================================\n",
            "\n",
            "0. MENENTUKAN TARGET VARIABEL\n",
            "------------------------------\n",
            "Kolom 'No' telah dihapus (tidak diperlukan untuk ML)\n",
            "Membuat kategori ISPU dari nilai ISPU...\n",
            "Distribusi kategori ISPU:\n",
            "ISPU_Kategori\n",
            "Baik                  359\n",
            "Sedang                167\n",
            "Tidak Sehat             0\n",
            "Sangat Tidak Sehat      0\n",
            "Berbahaya               0\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Jumlah kategori: 2\n",
            "\n",
            "Distribusi kelas (%):\n",
            "  Baik: 68.3%\n",
            "  Sedang: 31.7%\n",
            "  Tidak Sehat: 0.0%\n",
            "  Sangat Tidak Sehat: 0.0%\n",
            "  Berbahaya: 0.0%\n",
            "\n",
            "1. PENANGANAN MISSING VALUES\n",
            "------------------------------\n",
            "Tidak ada missing values\n",
            "\n",
            "2. PENANGANAN DATA DUPLIKAT\n",
            "------------------------------\n",
            "Menghapus 42 data duplikat\n",
            "Sisa 484 baris data\n",
            "\n",
            "3. ANALISIS OUTLIER (Hanya Informasi)\n",
            "------------------------------\n",
            "Outlier per kolom (batas IQR 1.5):\n",
            "  CO    :  63 outlier ( 13.0%)\n",
            "  NO2   :  29 outlier (  6.0%)\n",
            "  O3    :  86 outlier ( 17.8%)\n",
            "  PM10  :   9 outlier (  1.9%)\n",
            "  PM2.5 :  18 outlier (  3.7%)\n",
            "  SO2   :  46 outlier (  9.5%)\n",
            "\n",
            "4. PREPARASI TARGET VARIABEL\n",
            "------------------------------\n",
            "Mapping kategori ke angka:\n",
            "  0: Baik\n",
            "  1: Sedang\n",
            "  2: Tidak Sehat\n",
            "  3: Sangat Tidak Sehat\n",
            "  4: Berbahaya\n",
            "\n",
            "Target siap untuk modeling dengan LabelEncoder\n",
            "\n",
            "5. PREPARASI FEATURE DAN TARGET\n",
            "------------------------------\n",
            "Jumlah fitur: 6\n",
            "Jumlah sampel: 484\n",
            "Target classes: 2\n",
            "\n",
            "6. TRAIN-TEST SPLIT (STRATIFIED)\n",
            "------------------------------\n",
            "Train set: 387 samples (80.0%)\n",
            "Test set:  97 samples (20.0%)\n",
            "\n",
            "Distribusi kelas di Train set:\n",
            "ISPU_Kategori\n",
            "Baik                  253\n",
            "Sedang                134\n",
            "Tidak Sehat             0\n",
            "Sangat Tidak Sehat      0\n",
            "Berbahaya               0\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Distribusi kelas di Test set:\n",
            "ISPU_Kategori\n",
            "Baik                  64\n",
            "Sedang                33\n",
            "Tidak Sehat            0\n",
            "Sangat Tidak Sehat     0\n",
            "Berbahaya              0\n",
            "Name: count, dtype: int64\n",
            "\n",
            "7. SCALING (OPSIONAL - Hanya untuk referensi)\n",
            "------------------------------\n",
            "Random Forest TIDAK MEMERLUKAN scaling karena berbasis tree\n",
            "Namun, scaling bisa membantu visualisasi atau algoritma lain\n",
            "\n",
            "==================================================\n",
            "RINGKASAN AKHIR PREPROCESSING\n",
            "==================================================\n",
            "\n",
            "Dataset akhir:\n",
            "  Jumlah baris: 484\n",
            "  Jumlah kolom: 8\n",
            "  Fitur: ['CO', 'NO2', 'O3', 'PM10', 'PM2.5', 'SO2']\n",
            "  Target: ISPU_Kategori\n",
            "\n",
            "Statistik dataset:\n",
            "  Missing values: 0\n",
            "  Duplicates: 0\n",
            "\n",
            "Data siap untuk Random Forest Classifier!\n",
            "==================================================\n",
            "\n",
            "==================================================\n",
            "RINGKASAN AKHIR PREPROCESSING\n",
            "==================================================\n",
            "Data telah disimpan ke DataISPU_preprocessing.csv\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_17722c39-0473-40a5-ab4a-31a82c91f426\", \"DataISPU_preprocessing.csv\", 20293)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset akhir:\n",
            "  Jumlah baris: 484\n",
            "  Jumlah kolom: 8\n",
            "  Fitur: ['CO', 'NO2', 'O3', 'PM10', 'PM2.5', 'SO2']\n",
            "  Target: ISPU_Kategori\n"
          ]
        }
      ]
    }
  ]
}